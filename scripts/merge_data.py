#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤±æ™ºç—‡è©•ä¼°è³‡æ–™åˆä½µèˆ‡å ±è¡¨ç”Ÿæˆè…³æœ¬
Dementia Assessment Data Merger and Report Generator
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime

def load_all_json_files(data_dir='data'):
    """è¼‰å…¥æ‰€æœ‰ JSON æª”æ¡ˆ"""
    data_path = Path(data_dir)
    all_data = []
    
    if not data_path.exists():
        print(f"âš ï¸  è³‡æ–™å¤¾ {data_dir} ä¸å­˜åœ¨")
        return all_data
    
    json_files = list(data_path.glob('*.json'))
    print(f"ğŸ” æœå°‹åˆ° {len(json_files)} å€‹ JSON æª”æ¡ˆ")
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                data['_filename'] = json_file.name
                all_data.append(data)
                print(f"  âœ… æˆåŠŸè¼‰å…¥: {json_file.name}")
        except Exception as e:
            print(f"  âš ï¸  ç„¡æ³•è®€å– {json_file.name}: {e}")
    
    return all_data

def flatten_data(data_list):
    """å°‡åµŒå¥—çš„ JSON è³‡æ–™æ‰å¹³åŒ–ç‚ºè¡¨æ ¼"""
    rows = []
    
    for data in data_list:
        row = {
            # æª”æ¡ˆè³‡è¨Š
            'æª”æ¡ˆåç¨±': data.get('_filename', ''),
            'åŒ¯å‡ºæ™‚é–“': data.get('metadata', {}).get('exportDate', ''),
            'å·¥å…·ç‰ˆæœ¬': data.get('metadata', {}).get('toolVersion', ''),
            
            # åŸºæœ¬è³‡æ–™
            'ç—…æ‚£å§“å': data.get('patientInfo', {}).get('name', ''),
            'ç—…æ­·è™Ÿ': data.get('patientInfo', {}).get('chartNumber', ''),
            'å‡ºç”Ÿæ—¥æœŸ': data.get('patientInfo', {}).get('birthDate', ''),
            'å¹´é½¡': data.get('patientInfo', {}).get('age', ''),
            'æ€§åˆ¥': data.get('patientInfo', {}).get('gender', ''),
            'æ•™è‚²ç¨‹åº¦': data.get('patientInfo', {}).get('education', ''),
            'è©•ä¼°æ—¥æœŸ': data.get('patientInfo', {}).get('assessmentDate', ''),
            'è³‡è¨Šæä¾›è€…': data.get('patientInfo', {}).get('informantName', ''),
            'èˆ‡æ‚£è€…é—œä¿‚': data.get('patientInfo', {}).get('informantRelation', ''),
            
            # è©•ä¼°çµæœ
            'æ•´é«”é¢¨éšª': data.get('results', {}).get('overallRisk', ''),
            'ADLéšœç¤™ç¨‹åº¦': round(data.get('results', {}).get('adlImpairment', 0), 2),
            
            # å„é¡å‹å¤±æ™ºç—‡ç™¾åˆ†æ¯”
            'ADç™¾åˆ†æ¯”': round(data.get('results', {}).get('percentages', {}).get('AD', 0), 2),
            'DLBç™¾åˆ†æ¯”': round(data.get('results', {}).get('percentages', {}).get('DLB', 0), 2),
            'VaDç™¾åˆ†æ¯”': round(data.get('results', {}).get('percentages', {}).get('VaD', 0), 2),
            'FTDç™¾åˆ†æ¯”': round(data.get('results', {}).get('percentages', {}).get('FTD', 0), 2),
            'PPAç™¾åˆ†æ¯”': round(data.get('results', {}).get('percentages', {}).get('PPA', 0), 2),
            
            # ç›¸å°æ©Ÿç‡
            'ADç›¸å°æ©Ÿç‡': round(data.get('results', {}).get('probabilities', {}).get('AD', 0), 2),
            'DLBç›¸å°æ©Ÿç‡': round(data.get('results', {}).get('probabilities', {}).get('DLB', 0), 2),
            'VaDç›¸å°æ©Ÿç‡': round(data.get('results', {}).get('probabilities', {}).get('VaD', 0), 2),
            'FTDç›¸å°æ©Ÿç‡': round(data.get('results', {}).get('probabilities', {}).get('FTD', 0), 2),
            'PPAç›¸å°æ©Ÿç‡': round(data.get('results', {}).get('probabilities', {}).get('PPA', 0), 2),
            
            # æœ€å¯èƒ½çš„å¤±æ™ºç—‡é¡å‹
            'æœ€å¯èƒ½é¡å‹': '',
            'æœ€é«˜æ©Ÿç‡å€¼': 0,
            
            # ç•°å¸¸ç—‡ç‹€æ•¸é‡
            'ç•°å¸¸ç—‡ç‹€æ•¸': len(data.get('abnormalSymptoms', [])),
            
            # è‡¨åºŠå»ºè­°æ•¸é‡
            'è‡¨åºŠå»ºè­°æ•¸': len(data.get('recommendations', []))
        }
        
        # åˆ¤æ–·æœ€å¯èƒ½çš„å¤±æ™ºç—‡é¡å‹
        probs = data.get('results', {}).get('probabilities', {})
        if probs:
            max_type = max(probs, key=probs.get)
            max_prob = probs[max_type]
            row['æœ€å¯èƒ½é¡å‹'] = max_type
            row['æœ€é«˜æ©Ÿç‡å€¼'] = round(max_prob, 2)
        
        # åŠ å…¥æ‰€æœ‰å•é¡Œå›ç­”
        responses = data.get('responses', {})
        for key, value in responses.items():
            row[f'å›ç­”_{key}'] = value
        
        rows.append(row)
    
    return pd.DataFrame(rows)

def generate_summary_statistics(df):
    """ç”Ÿæˆæ‘˜è¦çµ±è¨ˆ"""
    summary = {}
    
    try:
        summary['ç¸½å€‹æ¡ˆæ•¸'] = len(df)
        
        if 'è©•ä¼°æ—¥æœŸ' in df.columns and len(df) > 0:
            dates = pd.to_datetime(df['è©•ä¼°æ—¥æœŸ'], errors='coerce')
            valid_dates = dates.dropna()
            if len(valid_dates) > 0:
                summary['æœ€æ—©è©•ä¼°æ—¥æœŸ'] = valid_dates.min().strftime('%Y-%m-%d')
                summary['æœ€æ™šè©•ä¼°æ—¥æœŸ'] = valid_dates.max().strftime('%Y-%m-%d')
        
        if 'å¹´é½¡' in df.columns:
            ages = pd.to_numeric(df['å¹´é½¡'], errors='coerce')
            valid_ages = ages.dropna()
            if len(valid_ages) > 0:
                summary['å¹³å‡å¹´é½¡'] = round(valid_ages.mean(), 1)
                summary['å¹´é½¡ä¸­ä½æ•¸'] = valid_ages.median()
                summary['æœ€å°å¹´é½¡'] = valid_ages.min()
                summary['æœ€å¤§å¹´é½¡'] = valid_ages.max()
        
        if 'æ€§åˆ¥' in df.columns:
            gender_counts = df['æ€§åˆ¥'].value_counts()
            for gender, count in gender_counts.items():
                summary[f'æ€§åˆ¥_{gender}'] = count
        
        if 'æ•´é«”é¢¨éšª' in df.columns:
            risk_counts = df['æ•´é«”é¢¨éšª'].value_counts()
            for risk, count in risk_counts.items():
                summary[f'é¢¨éšª_{risk}'] = count
        
        if 'ADLéšœç¤™ç¨‹åº¦' in df.columns:
            adl = pd.to_numeric(df['ADLéšœç¤™ç¨‹åº¦'], errors='coerce')
            valid_adl = adl.dropna()
            if len(valid_adl) > 0:
                summary['å¹³å‡ADLéšœç¤™ç¨‹åº¦'] = round(valid_adl.mean(), 2)
        
        if 'æœ€å¯èƒ½é¡å‹' in df.columns:
            type_counts = df['æœ€å¯èƒ½é¡å‹'].value_counts()
            for dtype, count in type_counts.items():
                summary[f'é¡å‹_{dtype}'] = count
        
    except Exception as e:
        print(f"âš ï¸  ç”Ÿæˆæ‘˜è¦çµ±è¨ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return summary

def create_pivot_tables(df):
    """å‰µå»ºæ¨ç´åˆ†æè¡¨"""
    pivot_tables = {}
    
    try:
        # æ€§åˆ¥èˆ‡é¢¨éšªç­‰ç´šäº¤å‰è¡¨
        if 'æ€§åˆ¥' in df.columns and 'æ•´é«”é¢¨éšª' in df.columns:
            pivot_tables['æ€§åˆ¥_é¢¨éšªäº¤å‰è¡¨'] = pd.crosstab(
                df['æ€§åˆ¥'], 
                df['æ•´é«”é¢¨éšª'], 
                margins=True, 
                margins_name='ç¸½è¨ˆ'
            )
        
        # å¹´é½¡çµ„èˆ‡å¤±æ™ºç—‡é¡å‹äº¤å‰è¡¨
        if 'å¹´é½¡' in df.columns and 'æœ€å¯èƒ½é¡å‹' in df.columns:
            df_copy = df.copy()
            df_copy['å¹´é½¡çµ„'] = pd.cut(
                pd.to_numeric(df_copy['å¹´é½¡'], errors='coerce'), 
                bins=[0, 60, 70, 80, 120], 
                labels=['<60', '60-69', '70-79', '80+']
            )
            pivot_tables['å¹´é½¡çµ„_é¡å‹äº¤å‰è¡¨'] = pd.crosstab(
                df_copy['å¹´é½¡çµ„'], 
                df_copy['æœ€å¯èƒ½é¡å‹'], 
                margins=True, 
                margins_name='ç¸½è¨ˆ'
            )
        
        # æ•™è‚²ç¨‹åº¦èˆ‡é¢¨éšªç­‰ç´šäº¤å‰è¡¨
        if 'æ•™è‚²ç¨‹åº¦' in df.columns and 'æ•´é«”é¢¨éšª' in df.columns:
            pivot_tables['æ•™è‚²ç¨‹åº¦_é¢¨éšªäº¤å‰è¡¨'] = pd.crosstab(
                df['æ•™è‚²ç¨‹åº¦'], 
                df['æ•´é«”é¢¨éšª'], 
                margins=True, 
                margins_name='ç¸½è¨ˆ'
            )
    
    except Exception as e:
        print(f"âš ï¸  å‰µå»ºæ¨ç´è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return pivot_tables

def main():
    print("=" * 60)
    print("ğŸš€ å¤±æ™ºç—‡è©•ä¼°è³‡æ–™è™•ç†ç³»çµ±")
    print("=" * 60)
    
    # è¼‰å…¥æ‰€æœ‰è³‡æ–™
    all_data = load_all_json_files('data')
    
    if len(all_data) == 0:
        print("\nâš ï¸  æ²’æœ‰æ‰¾åˆ°ä»»ä½•è©•ä¼°è³‡æ–™")
        print("ğŸ’¡ è«‹ç¢ºèª data/ è³‡æ–™å¤¾ä¸­æœ‰ JSON æª”æ¡ˆ")
        return
    
    print(f"\nâœ… æˆåŠŸè¼‰å…¥ {len(all_data)} å€‹è©•ä¼°æª”æ¡ˆ")
    
    # æ‰å¹³åŒ–è³‡æ–™
    print("\nğŸ”„ æ­£åœ¨è™•ç†è³‡æ–™...")
    df = flatten_data(all_data)
    print(f"âœ… è³‡æ–™è™•ç†å®Œæˆï¼Œå…± {len(df)} ç­†è¨˜éŒ„ï¼Œ{len(df.columns)} å€‹æ¬„ä½")
    
    # ç¢ºä¿ reports ç›®éŒ„å­˜åœ¨
    reports_path = Path('reports')
    reports_path.mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ™‚é–“æˆ³è¨˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # å„²å­˜ç‚º CSVï¼ˆå«æ™‚é–“æˆ³è¨˜ï¼‰
    print("\nğŸ“„ ç”Ÿæˆ CSV å ±è¡¨...")
    csv_path = f'reports/all_assessments_{timestamp}.csv'
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"  âœ… {csv_path}")
    
    # å„²å­˜ç‚º Excelï¼ˆå«æ™‚é–“æˆ³è¨˜ï¼‰
    print("\nğŸ“Š ç”Ÿæˆ Excel å ±è¡¨...")
    excel_path = f'reports/all_assessments_{timestamp}.xlsx'
    
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        # å®Œæ•´è³‡æ–™
        df.to_excel(writer, sheet_name='å®Œæ•´è³‡æ–™', index=False)
        print("  âœ… å·¥ä½œè¡¨: å®Œæ•´è³‡æ–™")
        
        # æ‘˜è¦çµ±è¨ˆ
        summary = generate_summary_statistics(df)
        if summary:
            summary_df = pd.DataFrame([summary]).T
            summary_df.columns = ['æ•¸å€¼']
            summary_df.to_excel(writer, sheet_name='æ‘˜è¦çµ±è¨ˆ')
            print("  âœ… å·¥ä½œè¡¨: æ‘˜è¦çµ±è¨ˆ")
        
        # é¢¨éšªåˆ†å¸ƒ
        if 'æ•´é«”é¢¨éšª' in df.columns:
            risk_dist = df['æ•´é«”é¢¨éšª'].value_counts().reset_index()
            risk_dist.columns = ['é¢¨éšªç­‰ç´š', 'å€‹æ¡ˆæ•¸']
            risk_dist['ç™¾åˆ†æ¯”'] = (risk_dist['å€‹æ¡ˆæ•¸'] / len(df) * 100).round(2)
            risk_dist.to_excel(writer, sheet_name='é¢¨éšªåˆ†å¸ƒ', index=False)
            print("  âœ… å·¥ä½œè¡¨: é¢¨éšªåˆ†å¸ƒ")
        
        # å¤±æ™ºç—‡é¡å‹åˆ†å¸ƒ
        if 'æœ€å¯èƒ½é¡å‹' in df.columns:
            type_dist = df['æœ€å¯èƒ½é¡å‹'].value_counts().reset_index()
            type_dist.columns = ['å¤±æ™ºç—‡é¡å‹', 'å€‹æ¡ˆæ•¸']
            type_dist['ç™¾åˆ†æ¯”'] = (type_dist['å€‹æ¡ˆæ•¸'] / len(df) * 100).round(2)
            type_dist.to_excel(writer, sheet_name='é¡å‹åˆ†å¸ƒ', index=False)
            print("  âœ… å·¥ä½œè¡¨: é¡å‹åˆ†å¸ƒ")
        
        # æ¨ç´åˆ†æè¡¨
        pivot_tables = create_pivot_tables(df)
        for name, pivot_df in pivot_tables.items():
            pivot_df.to_excel(writer, sheet_name=name)
            print(f"  âœ… å·¥ä½œè¡¨: {name}")
    
    print(f"\nâœ… Excel å ±è¡¨å·²ç”Ÿæˆ: {excel_path}")
    
    # ç”Ÿæˆæœ€æ–°ç‰ˆæœ¬ï¼ˆä¸å«æ™‚é–“æˆ³è¨˜ï¼Œç”¨æ–¼æŒçºŒæ›´æ–°ï¼‰
    print("\nğŸ“Œ ç”Ÿæˆæœ€æ–°ç‰ˆæœ¬...")
    df.to_csv('reports/all_assessments_latest.csv', index=False, encoding='utf-8-sig')
    
    with pd.ExcelWriter('reports/all_assessments_latest.xlsx', engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='å®Œæ•´è³‡æ–™', index=False)
        
        if summary:
            summary_df = pd.DataFrame([summary]).T
            summary_df.columns = ['æ•¸å€¼']
            summary_df.to_excel(writer, sheet_name='æ‘˜è¦çµ±è¨ˆ')
        
        if 'æ•´é«”é¢¨éšª' in df.columns:
            risk_dist = df['æ•´é«”é¢¨éšª'].value_counts().reset_index()
            risk_dist.columns = ['é¢¨éšªç­‰ç´š', 'å€‹æ¡ˆæ•¸']
            risk_dist['ç™¾åˆ†æ¯”'] = (risk_dist['å€‹æ¡ˆæ•¸'] / len(df) * 100).round(2)
            risk_dist.to_excel(writer, sheet_name='é¢¨éšªåˆ†å¸ƒ', index=False)
        
        if 'æœ€å¯èƒ½é¡å‹' in df.columns:
            type_dist = df['æœ€å¯èƒ½é¡å‹'].value_counts().reset_index()
            type_dist.columns = ['å¤±æ™ºç—‡é¡å‹', 'å€‹æ¡ˆæ•¸']
            type_dist['ç™¾åˆ†æ¯”'] = (type_dist['å€‹æ¡ˆæ•¸'] / len(df) * 100).round(2)
            type_dist.to_excel(writer, sheet_name='é¡å‹åˆ†å¸ƒ', index=False)
        
        for name, pivot_df in pivot_tables.items():
            pivot_df.to_excel(writer, sheet_name=name)
    
    print("  âœ… all_assessments_latest.csv")
    print("  âœ… all_assessments_latest.xlsx")
    
    print("\n" + "=" * 60)
    print("âœ¨ è™•ç†å®Œæˆï¼")
    print(f"ğŸ“Š å…±è™•ç† {len(all_data)} å€‹è©•ä¼°æª”æ¡ˆ")
    print(f"ğŸ“ å ±è¡¨ä½ç½®: reports/")
    print("=" * 60)

if __name__ == '__main__':
    main()